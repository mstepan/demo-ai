# Application configuration
# Avoid hardcoding secrets; prefer environment variables with defaults (e.g., ${VAR:default})

spring:
  application:
    name: demo-ai
  jackson:
    time-zone: UTC
    serialization:
      indent-output: false

  # OCI Generative AI configuration
  ai:
    oci:
      genai:
        # Region where your OCI GenAI endpoint is provisioned
        region: us-chicago-1

        # Use ~/.oci/config (session token profile created with:
        #   oci session authenticate --region us-chicago-1 --profile-name bmc_operator_access
        #)
        authenticationType: file
        profile: bmc_operator_access
        tenantId: ocid1.tenancy.oc1..aaaaaaaaqkcilbifc6tm4wlnefa2ofmazjqgdhodaqtsgrnrbbenkahkf62a

        # Spring AI OCI GenAI Chat configuration (Llama on OCI)
        # Model catalog: https://docs.oracle.com/en-us/iaas/Content/generative-ai/pretrained-models.htm
        cohere:
          chat:
            options:
              # Meta Llama model on OCI GenAI
              model: meta.llama-4-maverick-17b-128e-instruct-fp8
              # Compartment where the on-demand model is accessible
              compartment: ocid1.compartment.oc1..aaaaaaaadwjibfornz4simrjcqftsoxvnyn5syxqklv76e5rjmbucvkbvuwa
              # on-demand or dedicated
              servingMode: on-demand

server:
  port: 7171
  shutdown: graceful
  http2:
    enabled: true
  compression:
    enabled: true
    mime-types: text/html,text/xml,text/plain,text/css,text/javascript,application/javascript,application/json,application/xml
    min-response-size: 1024

logging:
  level:
    root: INFO
    org.springframework: INFO
    org.springframework.web: INFO
    com.github.mstepan: INFO
    com.oracle.bmc: DEBUG
    org.springframework.ai.oci: DEBUG

info:
  app:
    name: demo-ai
    description: Demo AI Spring Boot Project + OCI and Oracle 23ai DB
    version: ${APP_VERSION:0.0.1-SNAPSHOT}
